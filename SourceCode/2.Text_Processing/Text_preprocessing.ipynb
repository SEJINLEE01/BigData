{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b88b102-6c47-4489-914d-56aa217bfedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install konlpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3396c838-d7b9-42a9-bb76-34e7adefc9d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "from konlpy.tag import Okt\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Okt 로드\n",
    "okt = Okt()\n",
    "\n",
    "# 불용어 리스트\n",
    "with open(\"stopwords-ko.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    stopwords = set([line.strip() for line in f if line.strip()])\n",
    "\n",
    "# 복합어(신조어 등) 치환 사전\n",
    "compound_words = [\n",
    "    '가성비', '글라시에', '보냉', '세일', '잘', '색깔별로', '피오니', '사이즈', '벤티', '오리지널', '수밀감', '수준급', '충동구매',\n",
    "    '충동 구매', '신학기', '그립감', '선물용', '허접', '사은품', '빈플러스', '이중구조', '재구매', '데이오프', '킨토', '연마제', '오랜만',\n",
    "    '속상', '샌드 베이지', '보온', '끄떡없', '강추', '추운날', '보온력', '샌드베이지'\n",
    "]\n",
    "\n",
    "# 복합어 치환 함수\n",
    "def merge_compounds(text):\n",
    "    for word in compound_words:\n",
    "        if word in text:\n",
    "            # 복합어를 _로 이어서 치환 (예: '가성비' -> '가_성_비')\n",
    "            text = text.replace(word, '_'.join(list(word)))\n",
    "    return text\n",
    "\n",
    "# 전처리 함수 정의\n",
    "def preprocess_review(review):\n",
    "    if pd.isna(review):\n",
    "        return []\n",
    "\n",
    "    # 복합어 치환\n",
    "    review = merge_compounds(review)\n",
    "\n",
    "    # 특수문자 제거 및 정리\n",
    "    review = re.sub(r'[^\\uAC00-\\uD7A3a-zA-Z0-9\\s]', '', str(review)).strip()\n",
    "    review = re.sub(r'[^\\uAC00-\\uD7A3 0-9\\s]', '', review).strip()\n",
    "\n",
    "    # 형태소 분석\n",
    "    morphs = okt.pos(review, stem=True)\n",
    "\n",
    "    tokens = []\n",
    "    for word, tag in morphs:\n",
    "        if word in stopwords:\n",
    "            continue\n",
    "        if tag in ['Verb', 'Adjective']:\n",
    "            tokens.append(word)\n",
    "        elif tag in ['Noun', 'Alpha']:\n",
    "            tokens.append(word)\n",
    "        elif tag == 'Modifier':\n",
    "            tokens.append(word)\n",
    "    return tokens\n",
    "\n",
    "# 후처리: 치환된 복합어를 원래대로 복원\n",
    "def restore_compounds(tokens):\n",
    "    restored = []\n",
    "    buffer = \"\"\n",
    "    for token in tokens:\n",
    "        if token == \"_\":\n",
    "            continue\n",
    "        buffer += token\n",
    "        if buffer.replace(\"_\", \"\") in compound_words:\n",
    "            restored.append(buffer.replace(\"_\", \"\"))  # 복합어 원래 형태로 복원\n",
    "            buffer = \"\"\n",
    "        else:\n",
    "            restored.append(token)\n",
    "            buffer = \"\"\n",
    "    return restored\n",
    "\n",
    "# 처리할 파일 리스트\n",
    "review_files = [\n",
    "    \"review_data/beanplus_reviews.csv\",\n",
    "    \"review_data/kinto_reviews.csv\",\n",
    "    \"review_data/konu_reviews.csv\",\n",
    "    \"review_data/locknlock_reviews.csv\",\n",
    "    \"review_data/mosh_reviews.csv\",\n",
    "    \"review_data/stanley_reviews.csv\"\n",
    "]\n",
    "\n",
    "output_dir = \"preprocessed_data\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# 전처리 및 저장\n",
    "tqdm.pandas()\n",
    "\n",
    "for file in review_files:\n",
    "    try:\n",
    "        df = pd.read_csv(file, encoding='utf-8')\n",
    "    except UnicodeDecodeError:\n",
    "        df = pd.read_csv(file, encoding='cp949')\n",
    "        \n",
    "    review_column = 'review'\n",
    "\n",
    "    # 결측값 제거 및 중복 제거\n",
    "    df = df.dropna(subset=[review_column])\n",
    "    df = df.drop_duplicates(subset=[review_column])\n",
    "\n",
    "    # 전처리 적용\n",
    "    df['tokens'] = df[review_column].progress_apply(preprocess_review)\n",
    "\n",
    "    # 후처리: 복합어 복원\n",
    "    df['tokens'] = df['tokens'].apply(restore_compounds)\n",
    "\n",
    "    # 파일 저장\n",
    "    base_name = os.path.basename(file)\n",
    "    output_file = os.path.join(output_dir, base_name.replace('.csv', '_preprocessed_okt.csv'))\n",
    "    df.to_csv(output_file, encoding=\"utf-8-sig\", index=False)\n",
    "    print(f\"Saved: {output_file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
